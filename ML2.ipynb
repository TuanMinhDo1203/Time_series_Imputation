{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc29d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "\n",
    "# Optional: thêm XGBoost và LightGBM nếu dùng\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f112266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_outliers_iqr(data, threshold=3.0):\n",
    "    \"\"\"\n",
    "    Replace outliers (outside Q1 - threshold*IQR and Q3 + threshold*IQR)\n",
    "    with mean of non-outlier values.\n",
    "    \"\"\"\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - threshold * iqr\n",
    "    upper_bound = q3 + threshold * iqr\n",
    "    \n",
    "    mask = (data >= lower_bound) & (data <= upper_bound)\n",
    "    mean_value = data[mask].mean()\n",
    "    \n",
    "    clean_data = np.where(mask, data, mean_value)\n",
    "    return clean_data\n",
    "def min_max_scale(data):\n",
    "    \"\"\"\n",
    "    Scale data to range [0, 1] and return scaled data with inverse function.\n",
    "    \"\"\"\n",
    "    data_min = np.min(data)\n",
    "    data_max = np.max(data)\n",
    "    \n",
    "    scaled = (data - data_min) / (data_max - data_min)\n",
    "    \n",
    "    def inverse(scaled_data):\n",
    "        return scaled_data * (data_max - data_min) + data_min\n",
    "    \n",
    "    return scaled, inverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d233ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_model(model_type='RF'):\n",
    "    if model_type == 'RF':\n",
    "        model_f = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model_b = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'XGB':\n",
    "        model_f = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "        model_b = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "    elif model_type == 'LGBM':\n",
    "        model_f = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42, verbosity=-1)\n",
    "        model_b = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42, verbosity=-1)\n",
    "    elif model_type == 'SVR':\n",
    "        model_f = SVR(C=1.0, kernel='rbf')\n",
    "        model_b = SVR(C=1.0, kernel='rbf')\n",
    "    elif model_type == 'LR':\n",
    "        model_f = LinearRegression()\n",
    "        model_b = LinearRegression()\n",
    "    else:\n",
    "        raise ValueError(f\"Model type '{model_type}' is not supported.\")\n",
    "    return model_f, model_b\n",
    "\n",
    "def create_multiple_gaps(data_length, gap_size, num_gaps=1, mode='size'):\n",
    "    \"\"\"\n",
    "    mode='size': gap_size là số lượng phần tử (int)\n",
    "    mode='ratio': gap_size là phần trăm dữ liệu (float, ví dụ 0.02)\n",
    "    \"\"\"\n",
    "    positions = []\n",
    "    for _ in range(num_gaps):\n",
    "        if mode == 'ratio':\n",
    "            size = int(data_length * gap_size)\n",
    "        else:\n",
    "            size = gap_size\n",
    "        if size >= data_length:\n",
    "            raise ValueError(\"Gap size too large compared to data length.\")\n",
    "        start = random.randint(0, data_length - size)\n",
    "        positions.extend(range(start, start + size))\n",
    "    return sorted(set(positions)), size\n",
    "\n",
    "def to_supervised(data, T):\n",
    "    X, y = [], []\n",
    "    for i in range(T, len(data)):\n",
    "        if not np.isnan(data[i]) and not np.isnan(data[i-T:i]).any():\n",
    "            X.append(data[i-T:i])\n",
    "            y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def impute_gap(data, missing_positions, T, model_type='RF'):\n",
    "    data_imputed = data.copy()\n",
    "    N = len(data)\n",
    "    gaps = []\n",
    "    current_gap = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if i in missing_positions:\n",
    "            current_gap.append(i)\n",
    "        else:\n",
    "            if current_gap:\n",
    "                gaps.append(current_gap)\n",
    "                current_gap = []\n",
    "    if current_gap:\n",
    "        gaps.append(current_gap)\n",
    "\n",
    "    for gap in gaps:\n",
    "        start = gap[0]\n",
    "        end = gap[-1]\n",
    "\n",
    "        Db = data_imputed[:start]\n",
    "        Da = data_imputed[end+1:]\n",
    "\n",
    "        Xf, yf = to_supervised(Db, T)\n",
    "        Xb, yb = to_supervised(Da[::-1], T)\n",
    "\n",
    "        model_f, model_b = get_model(model_type)\n",
    "\n",
    "        use_forward = False\n",
    "        use_backward = False\n",
    "        if start < 3*T:\n",
    "            use_backward = True\n",
    "        elif end > N - 3*T:\n",
    "            use_forward = True\n",
    "        else:\n",
    "            use_forward = True\n",
    "            use_backward = True\n",
    "\n",
    "        x_fc, x_bc = [], []\n",
    "\n",
    "        if use_forward and len(Xf) > 0 and len(Db) >= T:\n",
    "            model_f.fit(Xf, yf)\n",
    "            last_known = Db[-T:]\n",
    "            for _ in range(len(gap)):\n",
    "                if np.isnan(last_known).any():\n",
    "                    break\n",
    "                pred = model_f.predict([last_known])[0]\n",
    "                x_fc.append(pred)\n",
    "                last_known = np.roll(last_known, -1)\n",
    "                last_known[-1] = pred\n",
    "\n",
    "        if use_backward and len(Xb) > 0 and len(Da) >= T:\n",
    "            model_b.fit(Xb, yb)\n",
    "            last_known_b = Da[:T][::-1]\n",
    "            for _ in range(len(gap)):\n",
    "                if np.isnan(last_known_b).any():\n",
    "                    break\n",
    "                pred_b = model_b.predict([last_known_b])[0]\n",
    "                x_bc.append(pred_b)\n",
    "                last_known_b = np.roll(last_known_b, -1)\n",
    "                last_known_b[-1] = pred_b\n",
    "            x_bc = x_bc[::-1]\n",
    "\n",
    "        # --- MEOW: tính lỗi và trọng số ---\n",
    "        val_len = min(10, len(Xf), len(Xb))\n",
    "\n",
    "        pred_f = model_f.predict(Xf[-val_len:]) if use_forward and len(Xf) >= val_len else []\n",
    "        pred_b = model_b.predict(Xb[-val_len:]) if use_backward and len(Xb) >= val_len else []\n",
    "\n",
    "        true_f = yf[-val_len:] if len(yf) >= val_len else []\n",
    "        true_b = yb[-val_len:] if len(yb) >= val_len else []\n",
    "\n",
    "        error_f = mean_absolute_error(true_f, pred_f) if len(pred_f) > 0 else np.inf\n",
    "        error_b = mean_absolute_error(true_b, pred_b) if len(pred_b) > 0 else np.inf\n",
    "\n",
    "        if np.isfinite(error_f) and np.isfinite(error_b):\n",
    "            wf = 1 / error_f\n",
    "            wb = 1 / error_b\n",
    "            wf = wf / (wf + wb)\n",
    "            wb = 1 - wf\n",
    "        else:\n",
    "            wf = wb = 0.5\n",
    "\n",
    "        # --- Điền giá trị đã nội suy vào ---\n",
    "        for idx, pos in enumerate(gap):\n",
    "            f_val = x_fc[idx] if idx < len(x_fc) else np.nan\n",
    "            b_val = x_bc[idx] if idx < len(x_bc) else np.nan\n",
    "\n",
    "            if use_forward and use_backward:\n",
    "                if not np.isnan(f_val) and not np.isnan(b_val):\n",
    "                    data_imputed[pos] = wf * f_val + wb * b_val  # MEOW weighting\n",
    "                elif not np.isnan(f_val):\n",
    "                    data_imputed[pos] = f_val\n",
    "                elif not np.isnan(b_val):\n",
    "                    data_imputed[pos] = b_val\n",
    "            elif use_forward and not np.isnan(f_val):\n",
    "                data_imputed[pos] = f_val\n",
    "            elif use_backward and not np.isnan(b_val):\n",
    "                data_imputed[pos] = b_val\n",
    "            else:\n",
    "                data_imputed[pos] = np.nan\n",
    "\n",
    "    return data_imputed\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Fractional Bias\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    fb = 2 * abs((mean_pred - mean_true) / (mean_pred + mean_true))\n",
    "    \n",
    "    # Fractional Standard Deviation\n",
    "    sd_true = np.std(y_true)\n",
    "    sd_pred = np.std(y_pred)\n",
    "    fsd = 2 * abs((sd_true - sd_pred) / (sd_true + sd_pred))\n",
    "    \n",
    "    # Similarity\n",
    "    T = len(y_true)\n",
    "    range_x = np.max(y_true) - np.min(y_true)\n",
    "    if range_x == 0:\n",
    "        sim = 1.0 if np.allclose(y_true, y_pred) else 0.0\n",
    "    else:\n",
    "        diff_sum = np.sum(1/(1+(np.abs(y_true - y_pred) / range_x)))\n",
    "        sim = diff_sum / T\n",
    "        \n",
    "    return {'SIM': sim, 'MAE': mae, 'RMSE': rmse, 'FB': fb, 'FSD': fsd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ec329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute_gap(data, missing_positions, T, model_type='RF'):\n",
    "#     data_imputed = data.copy()\n",
    "#     N = len(data)\n",
    "#     gaps = []\n",
    "#     current_gap = []\n",
    "\n",
    "#     for i in range(len(data)):\n",
    "#         if i in missing_positions:\n",
    "#             current_gap.append(i)\n",
    "#         else:\n",
    "#             if current_gap:\n",
    "#                 gaps.append(current_gap)\n",
    "#                 current_gap = []\n",
    "#     if current_gap:\n",
    "#         gaps.append(current_gap)\n",
    "\n",
    "#     for gap in gaps:\n",
    "#         start = gap[0]\n",
    "#         end = gap[-1]\n",
    "\n",
    "#         Db = data_imputed[:start]\n",
    "#         Da = data_imputed[end+1:]\n",
    "\n",
    "#         Xf, yf = to_supervised(Db, T)\n",
    "#         Xb, yb = to_supervised(Da[::-1], T)\n",
    "\n",
    "#         model_f, model_b = get_model(model_type)\n",
    "\n",
    "#         use_forward = False\n",
    "#         use_backward = False\n",
    "#         if start < 3*T:\n",
    "#             use_backward = True\n",
    "#         elif end > N - 3*T:\n",
    "#             use_forward = True\n",
    "#         else:\n",
    "#             use_forward = True\n",
    "#             use_backward = True\n",
    "\n",
    "#         x_fc, x_bc = [], []\n",
    "\n",
    "#         if use_forward and len(Xf) > 0 and len(Db) >= T:\n",
    "#             model_f.fit(Xf, yf)\n",
    "#             last_known = Db[-T:]\n",
    "#             for _ in range(len(gap)):\n",
    "#                 if np.isnan(last_known).any():\n",
    "#                     break\n",
    "#                 pred = model_f.predict([last_known])[0]\n",
    "#                 x_fc.append(pred)\n",
    "#                 last_known = np.roll(last_known, -1)\n",
    "#                 last_known[-1] = pred\n",
    "\n",
    "#         if use_backward and len(Xb) > 0 and len(Da) >= T:\n",
    "#             model_b.fit(Xb, yb)\n",
    "#             last_known_b = Da[:T][::-1]\n",
    "#             for _ in range(len(gap)):\n",
    "#                 if np.isnan(last_known_b).any():\n",
    "#                     break\n",
    "#                 pred_b = model_b.predict([last_known_b])[0]\n",
    "#                 x_bc.append(pred_b)\n",
    "#                 last_known_b = np.roll(last_known_b, -1)\n",
    "#                 last_known_b[-1] = pred_b\n",
    "#             x_bc = x_bc[::-1]\n",
    "\n",
    "#         for idx, pos in enumerate(gap):\n",
    "#             f_val = x_fc[idx] if idx < len(x_fc) else np.nan\n",
    "#             b_val = x_bc[idx] if idx < len(x_bc) else np.nan\n",
    "\n",
    "#             if use_forward and use_backward:\n",
    "#                 if not np.isnan(f_val) and not np.isnan(b_val):\n",
    "#                     data_imputed[pos] = (f_val + b_val) / 2\n",
    "#                 elif not np.isnan(f_val):\n",
    "#                     data_imputed[pos] = f_val\n",
    "#                 elif not np.isnan(b_val):\n",
    "#                     data_imputed[pos] = b_val\n",
    "#             elif use_forward and not np.isnan(f_val):\n",
    "#                 data_imputed[pos] = f_val\n",
    "#             elif use_backward and not np.isnan(b_val):\n",
    "#                 data_imputed[pos] = b_val\n",
    "#             else:\n",
    "#                 data_imputed[pos] = np.nan\n",
    "\n",
    "#     return data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0233056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(data, gap_inputs, input_type='size', num_runs=10, model_type='RF', \n",
    "                remove_outliers=True, scale_data=True, outlier_threshold=3.0, fixed_positions=None):\n",
    "    \"\"\"\n",
    "    Complete pipeline including preprocessing and imputation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Input time series data\n",
    "    gap_inputs : list\n",
    "        List of gap sizes or ratios\n",
    "    input_type : str, optional (default='size')\n",
    "        'size' for number of elements or 'ratio' for percentage\n",
    "    num_runs : int, optional (default=10)\n",
    "        Number of experiment runs\n",
    "    model_type : str, optional (default='RF')\n",
    "        Type of model to use ('RF', 'XGB', 'LGBM', 'SVR', 'LR')\n",
    "    remove_outliers : bool, optional (default=True)\n",
    "        Whether to remove outliers using IQR method\n",
    "    scale_data : bool, optional (default=True)\n",
    "        Whether to scale data to [0,1] range\n",
    "    outlier_threshold : float, optional (default=3.0)\n",
    "        Threshold for IQR outlier removal\n",
    "    fixed_positions : dict, optional (default=None)\n",
    "        Dictionary of pre-generated gap positions for each gap_input and run\n",
    "        Format: {gap_input: {run_number: (positions, size)}}\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (results, gap_positions)\n",
    "        - results: List of tuples (gap_input, average_scores)\n",
    "        - gap_positions: Dictionary of gap positions used for each gap_input and run\n",
    "    \"\"\"\n",
    "    # Preprocessing\n",
    "    processed_data = data.copy()\n",
    "    \n",
    "    if remove_outliers:\n",
    "        processed_data = remove_outliers_iqr(processed_data, threshold=outlier_threshold)\n",
    "    \n",
    "    if scale_data:\n",
    "        processed_data, inverse_scale = min_max_scale(processed_data)\n",
    "    \n",
    "    # Generate or use fixed gap positions\n",
    "    if fixed_positions is None:\n",
    "        gap_positions = {}\n",
    "        for gap_input in gap_inputs:\n",
    "            gap_positions[gap_input] = {}\n",
    "            for run in range(num_runs):\n",
    "                positions, size = create_multiple_gaps(len(processed_data), gap_input, \n",
    "                                                    num_gaps=1, mode=input_type)\n",
    "                gap_positions[gap_input][run] = (positions, size)\n",
    "    else:\n",
    "        gap_positions = fixed_positions\n",
    "    \n",
    "    # Run experiments\n",
    "    all_results = []\n",
    "    for gap_input in gap_inputs:\n",
    "        print(f\"\\n==> Gap:\", gap_input*100 if input_type=='ratio' else gap_input)\n",
    "        results = []\n",
    "\n",
    "        for run in range(num_runs):\n",
    "            data_missing = processed_data.copy()\n",
    "            missing_positions, gap_size = gap_positions[gap_input][run]\n",
    "            \n",
    "            # Create gaps\n",
    "            for pos in missing_positions:\n",
    "                data_missing[pos] = np.nan\n",
    "\n",
    "            # Impute\n",
    "            # print(gap_size)\n",
    "            imputed_data = impute_gap(data_missing, missing_positions, T=gap_size, model_type=model_type)\n",
    "\n",
    "            # Transform back if scaled\n",
    "            if scale_data:\n",
    "                imputed_data = inverse_scale(imputed_data)\n",
    "                # processed_data = inverse_scale(processed_data)\n",
    "\n",
    "            # Evaluate\n",
    "            y_true = data[missing_positions]\n",
    "            y_pred = imputed_data[missing_positions]\n",
    "            score = evaluate_metrics(y_true, y_pred)\n",
    "            results.append(score)\n",
    "\n",
    "        # Average results\n",
    "        avg_score = {k: np.mean([r[k] for r in results]) for k in results[0]}\n",
    "        all_results.append((gap_input, avg_score))\n",
    "        print(f\"→ Average metrics: {avg_score}\")\n",
    "\n",
    "    return all_results, gap_positions\n",
    "\n",
    "def run_multiple_models(data, gap_inputs, model_types, input_type='size', num_runs=10,\n",
    "                       remove_outliers=True, scale_data=True, outlier_threshold=3.0, fixed_positions=None):\n",
    "    \"\"\"\n",
    "    Run multiple models with the same gap positions for fair comparison\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Input time series data\n",
    "    gap_inputs : list\n",
    "        List of gap sizes or ratios\n",
    "    model_types : list\n",
    "        List of model types to evaluate ('RF', 'XGB', 'LGBM', 'SVR', 'LR')\n",
    "    Other parameters are same as run_pipeline\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with results for each model and the gap positions used\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    i=0\n",
    "    if fixed_positions==None:\n",
    "        i=1\n",
    "    # First run to generate gap position\n",
    "        first_model = model_types[0]\n",
    "        print(f\"\\n=========={first_model} Results==========\")\n",
    "        model_results, gap_positions = run_pipeline(\n",
    "            data=data,\n",
    "            gap_inputs=gap_inputs,\n",
    "            input_type=input_type,\n",
    "            num_runs=num_runs,\n",
    "            model_type=first_model,\n",
    "            remove_outliers=remove_outliers,\n",
    "            scale_data=scale_data,\n",
    "            outlier_threshold=outlier_threshold\n",
    "        )\n",
    "        results[first_model] = model_results\n",
    "    else:\n",
    "        gap_positions=fixed_positions\n",
    "    # Run remaining models with same gap positions\n",
    "    for model_type in model_types[i:]:\n",
    "        print(f\"\\n=========={model_type} Results==========\")\n",
    "        model_results, _ = run_pipeline(\n",
    "            data=data,\n",
    "            gap_inputs=gap_inputs,\n",
    "            input_type=input_type,\n",
    "            num_runs=num_runs,\n",
    "            model_type=model_type,\n",
    "            remove_outliers=remove_outliers,\n",
    "            scale_data=scale_data,\n",
    "            outlier_threshold=outlier_threshold,\n",
    "            fixed_positions=gap_positions\n",
    "        )\n",
    "        results[model_type] = model_results\n",
    "    \n",
    "    return {\n",
    "        'results': results,\n",
    "        'gap_positions': gap_positions\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c7c2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu txt mỗi dòng 1 số\n",
    "data_batri = np.loadtxt(r'D:\\Learn\\Kì 5\\DPL302m\\Dataset\\batri_temp.txt')\n",
    "gap_sizes = [0.006, 0.0075, 0.01, 0.0125, 0.015]\n",
    "model_type_list = [ 'SVR','RF','LGBM','LR', 'XGB']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623a81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\Learn\\Kì 5\\DPL302m\\CODE\\batri_gap_positions.json\", \"r\") as f:\n",
    "    batri_fixed_positions = json.load(f)\n",
    "\n",
    "# Chuyển key string → float + int (nếu cần)\n",
    "batri_fixed_positions = {\n",
    "    float(gap): {int(run): (positions, size)\n",
    "        for run, (positions, size) in run_dict.items()}\n",
    "    for gap, run_dict in batri_fixed_positions.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0672a886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========SVR Results==========\n",
      "\n",
      "==> Gap: 0.6\n",
      "→ Average metrics: {'SIM': 0.890331503487572, 'MAE': 12.803305149053694, 'RMSE': 17.034978872866436, 'FB': 0.024582938150381834, 'FSD': 0.23210405578692272}\n",
      "\n",
      "==> Gap: 0.75\n",
      "→ Average metrics: {'SIM': 0.8966631950883338, 'MAE': 11.72008825723229, 'RMSE': 14.298979379552142, 'FB': 0.033006721605193176, 'FSD': 0.16094567627042494}\n",
      "\n",
      "==> Gap: 1.0\n",
      "→ Average metrics: {'SIM': 0.9051307639906625, 'MAE': 10.297556451440714, 'RMSE': 13.412360217801728, 'FB': 0.015110759266036089, 'FSD': 0.19295032041146482}\n",
      "\n",
      "==> Gap: 1.25\n",
      "→ Average metrics: {'SIM': 0.905149040783266, 'MAE': 11.357751820394563, 'RMSE': 14.950535176385273, 'FB': 0.018395993058008587, 'FSD': 0.16109237059869091}\n",
      "\n",
      "==> Gap: 1.5\n",
      "→ Average metrics: {'SIM': 0.9044799991327614, 'MAE': 11.212819662519653, 'RMSE': 14.956306090172927, 'FB': 0.023590504751302633, 'FSD': 0.10491361145622305}\n",
      "\n",
      "==========RF Results==========\n",
      "\n",
      "==> Gap: 0.6\n",
      "→ Average metrics: {'SIM': 0.8915431657702777, 'MAE': 12.585444071518358, 'RMSE': 16.476572505622585, 'FB': 0.022980704577178386, 'FSD': 0.20575519198858103}\n",
      "\n",
      "==> Gap: 0.75\n",
      "→ Average metrics: {'SIM': 0.9003038440427348, 'MAE': 11.306633017632976, 'RMSE': 14.217791630399427, 'FB': 0.02961060213430764, 'FSD': 0.23033399012941674}\n",
      "\n",
      "==> Gap: 1.0\n",
      "→ Average metrics: {'SIM': 0.9075216362852737, 'MAE': 10.03904650712079, 'RMSE': 12.848161752056873, 'FB': 0.011618155971119527, 'FSD': 0.15978676959702615}\n",
      "\n",
      "==> Gap: 1.25\n",
      "→ Average metrics: {'SIM': 0.9005136581465767, 'MAE': 11.848050295856698, 'RMSE': 15.252654425034427, 'FB': 0.02054875687138123, 'FSD': 0.1976995555107207}\n",
      "\n",
      "==> Gap: 1.5\n",
      "→ Average metrics: {'SIM': 0.9120641092888768, 'MAE': 10.171422375477231, 'RMSE': 13.472364952246798, 'FB': 0.016575105214577536, 'FSD': 0.12210530707005458}\n",
      "\n",
      "==========LGBM Results==========\n",
      "\n",
      "==> Gap: 0.6\n",
      "→ Average metrics: {'SIM': 0.8914623563972086, 'MAE': 12.539839371722612, 'RMSE': 16.561991234250968, 'FB': 0.026136231455053067, 'FSD': 0.2045583438958317}\n",
      "\n",
      "==> Gap: 0.75\n",
      "→ Average metrics: {'SIM': 0.909042463170948, 'MAE': 10.185830890653904, 'RMSE': 12.84096014823226, 'FB': 0.023764922506495825, 'FSD': 0.15149970303505542}\n",
      "\n",
      "==> Gap: 1.0\n",
      "→ Average metrics: {'SIM': 0.9006460423554877, 'MAE': 10.753669635655744, 'RMSE': 13.719632272102412, 'FB': 0.014088215909205833, 'FSD': 0.1423907659284369}\n",
      "\n",
      "==> Gap: 1.25\n",
      "→ Average metrics: {'SIM': 0.8827383324615152, 'MAE': 14.055783142408362, 'RMSE': 17.803613172970397, 'FB': 0.028154922976432357, 'FSD': 0.14787091750560155}\n",
      "\n",
      "==> Gap: 1.5\n",
      "→ Average metrics: {'SIM': 0.9033398256378113, 'MAE': 11.436619175370963, 'RMSE': 14.818237642488196, 'FB': 0.0212914218701179, 'FSD': 0.08974300454011432}\n",
      "\n",
      "==========LR Results==========\n",
      "\n",
      "==> Gap: 0.6\n",
      "→ Average metrics: {'SIM': 0.8915588603114853, 'MAE': 12.538291661250204, 'RMSE': 16.312226039108545, 'FB': 0.021548811154888714, 'FSD': 0.2450966800185192}\n",
      "\n",
      "==> Gap: 0.75\n",
      "→ Average metrics: {'SIM': 0.9029637145361848, 'MAE': 11.076807195860164, 'RMSE': 13.625942936195946, 'FB': 0.02819159583279194, 'FSD': 0.20462007560908274}\n",
      "\n",
      "==> Gap: 1.0\n",
      "→ Average metrics: {'SIM': 0.9074565055129289, 'MAE': 9.981542308974806, 'RMSE': 12.895251395725575, 'FB': 0.010765349286706569, 'FSD': 0.143526466460952}\n",
      "\n",
      "==> Gap: 1.25\n",
      "→ Average metrics: {'SIM': 0.9032243419169312, 'MAE': 11.503797003956356, 'RMSE': 15.044493770919399, 'FB': 0.017913375476773803, 'FSD': 0.13549455813096328}\n",
      "\n",
      "==> Gap: 1.5\n",
      "→ Average metrics: {'SIM': 0.9123407005470062, 'MAE': 10.189785359224548, 'RMSE': 13.849683308658678, 'FB': 0.020519248104895287, 'FSD': 0.13989600111421474}\n",
      "\n",
      "==========XGB Results==========\n",
      "\n",
      "==> Gap: 0.6\n",
      "→ Average metrics: {'SIM': 0.8839484881110693, 'MAE': 13.552321620263578, 'RMSE': 17.581465514389073, 'FB': 0.029467748837062546, 'FSD': 0.20334909665361806}\n",
      "\n",
      "==> Gap: 0.75\n",
      "→ Average metrics: {'SIM': 0.899079797341727, 'MAE': 11.547085755202907, 'RMSE': 14.382948453613116, 'FB': 0.030176702695080094, 'FSD': 0.18651899966482696}\n",
      "\n",
      "==> Gap: 1.0\n",
      "→ Average metrics: {'SIM': 0.8992852118123873, 'MAE': 11.013380723145135, 'RMSE': 14.03870628837905, 'FB': 0.01642478958593776, 'FSD': 0.15391172296227856}\n",
      "\n",
      "==> Gap: 1.25\n",
      "→ Average metrics: {'SIM': 0.9005828440824415, 'MAE': 11.92640031460851, 'RMSE': 15.415297411272999, 'FB': 0.01630910855723152, 'FSD': 0.17774518526048197}\n",
      "\n",
      "==> Gap: 1.5\n",
      "→ Average metrics: {'SIM': 0.9069500292767613, 'MAE': 10.849672901785098, 'RMSE': 14.005945841977496, 'FB': 0.017595949429689617, 'FSD': 0.09524135448998489}\n"
     ]
    }
   ],
   "source": [
    "all_results = run_multiple_models(\n",
    "    data=data_batri,\n",
    "    gap_inputs=gap_sizes,\n",
    "    model_types=model_type_list,\n",
    "    input_type='ratio',\n",
    "    remove_outliers=False,\n",
    "    scale_data=False,\n",
    "    fixed_positions=batri_fixed_positions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05af852e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ([1843,\n",
       "   1844,\n",
       "   1845,\n",
       "   1846,\n",
       "   1847,\n",
       "   1848,\n",
       "   1849,\n",
       "   1850,\n",
       "   1851,\n",
       "   1852,\n",
       "   1853,\n",
       "   1854,\n",
       "   1855,\n",
       "   1856,\n",
       "   1857,\n",
       "   1858,\n",
       "   1859,\n",
       "   1860,\n",
       "   1861,\n",
       "   1862,\n",
       "   1863,\n",
       "   1864,\n",
       "   1865,\n",
       "   1866,\n",
       "   1867,\n",
       "   1868,\n",
       "   1869,\n",
       "   1870,\n",
       "   1871,\n",
       "   1872,\n",
       "   1873,\n",
       "   1874,\n",
       "   1875,\n",
       "   1876,\n",
       "   1877,\n",
       "   1878,\n",
       "   1879,\n",
       "   1880,\n",
       "   1881,\n",
       "   1882,\n",
       "   1883,\n",
       "   1884,\n",
       "   1885],\n",
       "  43),\n",
       " 1: ([2105,\n",
       "   2106,\n",
       "   2107,\n",
       "   2108,\n",
       "   2109,\n",
       "   2110,\n",
       "   2111,\n",
       "   2112,\n",
       "   2113,\n",
       "   2114,\n",
       "   2115,\n",
       "   2116,\n",
       "   2117,\n",
       "   2118,\n",
       "   2119,\n",
       "   2120,\n",
       "   2121,\n",
       "   2122,\n",
       "   2123,\n",
       "   2124,\n",
       "   2125,\n",
       "   2126,\n",
       "   2127,\n",
       "   2128,\n",
       "   2129,\n",
       "   2130,\n",
       "   2131,\n",
       "   2132,\n",
       "   2133,\n",
       "   2134,\n",
       "   2135,\n",
       "   2136,\n",
       "   2137,\n",
       "   2138,\n",
       "   2139,\n",
       "   2140,\n",
       "   2141,\n",
       "   2142,\n",
       "   2143,\n",
       "   2144,\n",
       "   2145,\n",
       "   2146,\n",
       "   2147],\n",
       "  43),\n",
       " 2: ([5248,\n",
       "   5249,\n",
       "   5250,\n",
       "   5251,\n",
       "   5252,\n",
       "   5253,\n",
       "   5254,\n",
       "   5255,\n",
       "   5256,\n",
       "   5257,\n",
       "   5258,\n",
       "   5259,\n",
       "   5260,\n",
       "   5261,\n",
       "   5262,\n",
       "   5263,\n",
       "   5264,\n",
       "   5265,\n",
       "   5266,\n",
       "   5267,\n",
       "   5268,\n",
       "   5269,\n",
       "   5270,\n",
       "   5271,\n",
       "   5272,\n",
       "   5273,\n",
       "   5274,\n",
       "   5275,\n",
       "   5276,\n",
       "   5277,\n",
       "   5278,\n",
       "   5279,\n",
       "   5280,\n",
       "   5281,\n",
       "   5282,\n",
       "   5283,\n",
       "   5284,\n",
       "   5285,\n",
       "   5286,\n",
       "   5287,\n",
       "   5288,\n",
       "   5289,\n",
       "   5290],\n",
       "  43),\n",
       " 3: ([821,\n",
       "   822,\n",
       "   823,\n",
       "   824,\n",
       "   825,\n",
       "   826,\n",
       "   827,\n",
       "   828,\n",
       "   829,\n",
       "   830,\n",
       "   831,\n",
       "   832,\n",
       "   833,\n",
       "   834,\n",
       "   835,\n",
       "   836,\n",
       "   837,\n",
       "   838,\n",
       "   839,\n",
       "   840,\n",
       "   841,\n",
       "   842,\n",
       "   843,\n",
       "   844,\n",
       "   845,\n",
       "   846,\n",
       "   847,\n",
       "   848,\n",
       "   849,\n",
       "   850,\n",
       "   851,\n",
       "   852,\n",
       "   853,\n",
       "   854,\n",
       "   855,\n",
       "   856,\n",
       "   857,\n",
       "   858,\n",
       "   859,\n",
       "   860,\n",
       "   861,\n",
       "   862,\n",
       "   863],\n",
       "  43),\n",
       " 4: ([3719,\n",
       "   3720,\n",
       "   3721,\n",
       "   3722,\n",
       "   3723,\n",
       "   3724,\n",
       "   3725,\n",
       "   3726,\n",
       "   3727,\n",
       "   3728,\n",
       "   3729,\n",
       "   3730,\n",
       "   3731,\n",
       "   3732,\n",
       "   3733,\n",
       "   3734,\n",
       "   3735,\n",
       "   3736,\n",
       "   3737,\n",
       "   3738,\n",
       "   3739,\n",
       "   3740,\n",
       "   3741,\n",
       "   3742,\n",
       "   3743,\n",
       "   3744,\n",
       "   3745,\n",
       "   3746,\n",
       "   3747,\n",
       "   3748,\n",
       "   3749,\n",
       "   3750,\n",
       "   3751,\n",
       "   3752,\n",
       "   3753,\n",
       "   3754,\n",
       "   3755,\n",
       "   3756,\n",
       "   3757,\n",
       "   3758,\n",
       "   3759,\n",
       "   3760,\n",
       "   3761],\n",
       "  43),\n",
       " 5: ([3197,\n",
       "   3198,\n",
       "   3199,\n",
       "   3200,\n",
       "   3201,\n",
       "   3202,\n",
       "   3203,\n",
       "   3204,\n",
       "   3205,\n",
       "   3206,\n",
       "   3207,\n",
       "   3208,\n",
       "   3209,\n",
       "   3210,\n",
       "   3211,\n",
       "   3212,\n",
       "   3213,\n",
       "   3214,\n",
       "   3215,\n",
       "   3216,\n",
       "   3217,\n",
       "   3218,\n",
       "   3219,\n",
       "   3220,\n",
       "   3221,\n",
       "   3222,\n",
       "   3223,\n",
       "   3224,\n",
       "   3225,\n",
       "   3226,\n",
       "   3227,\n",
       "   3228,\n",
       "   3229,\n",
       "   3230,\n",
       "   3231,\n",
       "   3232,\n",
       "   3233,\n",
       "   3234,\n",
       "   3235,\n",
       "   3236,\n",
       "   3237,\n",
       "   3238,\n",
       "   3239],\n",
       "  43),\n",
       " 6: ([916,\n",
       "   917,\n",
       "   918,\n",
       "   919,\n",
       "   920,\n",
       "   921,\n",
       "   922,\n",
       "   923,\n",
       "   924,\n",
       "   925,\n",
       "   926,\n",
       "   927,\n",
       "   928,\n",
       "   929,\n",
       "   930,\n",
       "   931,\n",
       "   932,\n",
       "   933,\n",
       "   934,\n",
       "   935,\n",
       "   936,\n",
       "   937,\n",
       "   938,\n",
       "   939,\n",
       "   940,\n",
       "   941,\n",
       "   942,\n",
       "   943,\n",
       "   944,\n",
       "   945,\n",
       "   946,\n",
       "   947,\n",
       "   948,\n",
       "   949,\n",
       "   950,\n",
       "   951,\n",
       "   952,\n",
       "   953,\n",
       "   954,\n",
       "   955,\n",
       "   956,\n",
       "   957,\n",
       "   958],\n",
       "  43),\n",
       " 7: ([3014,\n",
       "   3015,\n",
       "   3016,\n",
       "   3017,\n",
       "   3018,\n",
       "   3019,\n",
       "   3020,\n",
       "   3021,\n",
       "   3022,\n",
       "   3023,\n",
       "   3024,\n",
       "   3025,\n",
       "   3026,\n",
       "   3027,\n",
       "   3028,\n",
       "   3029,\n",
       "   3030,\n",
       "   3031,\n",
       "   3032,\n",
       "   3033,\n",
       "   3034,\n",
       "   3035,\n",
       "   3036,\n",
       "   3037,\n",
       "   3038,\n",
       "   3039,\n",
       "   3040,\n",
       "   3041,\n",
       "   3042,\n",
       "   3043,\n",
       "   3044,\n",
       "   3045,\n",
       "   3046,\n",
       "   3047,\n",
       "   3048,\n",
       "   3049,\n",
       "   3050,\n",
       "   3051,\n",
       "   3052,\n",
       "   3053,\n",
       "   3054,\n",
       "   3055,\n",
       "   3056],\n",
       "  43),\n",
       " 8: ([1143,\n",
       "   1144,\n",
       "   1145,\n",
       "   1146,\n",
       "   1147,\n",
       "   1148,\n",
       "   1149,\n",
       "   1150,\n",
       "   1151,\n",
       "   1152,\n",
       "   1153,\n",
       "   1154,\n",
       "   1155,\n",
       "   1156,\n",
       "   1157,\n",
       "   1158,\n",
       "   1159,\n",
       "   1160,\n",
       "   1161,\n",
       "   1162,\n",
       "   1163,\n",
       "   1164,\n",
       "   1165,\n",
       "   1166,\n",
       "   1167,\n",
       "   1168,\n",
       "   1169,\n",
       "   1170,\n",
       "   1171,\n",
       "   1172,\n",
       "   1173,\n",
       "   1174,\n",
       "   1175,\n",
       "   1176,\n",
       "   1177,\n",
       "   1178,\n",
       "   1179,\n",
       "   1180,\n",
       "   1181,\n",
       "   1182,\n",
       "   1183,\n",
       "   1184,\n",
       "   1185],\n",
       "  43),\n",
       " 9: ([7251,\n",
       "   7252,\n",
       "   7253,\n",
       "   7254,\n",
       "   7255,\n",
       "   7256,\n",
       "   7257,\n",
       "   7258,\n",
       "   7259,\n",
       "   7260,\n",
       "   7261,\n",
       "   7262,\n",
       "   7263,\n",
       "   7264,\n",
       "   7265,\n",
       "   7266,\n",
       "   7267,\n",
       "   7268,\n",
       "   7269,\n",
       "   7270,\n",
       "   7271,\n",
       "   7272,\n",
       "   7273,\n",
       "   7274,\n",
       "   7275,\n",
       "   7276,\n",
       "   7277,\n",
       "   7278,\n",
       "   7279,\n",
       "   7280,\n",
       "   7281,\n",
       "   7282,\n",
       "   7283,\n",
       "   7284,\n",
       "   7285,\n",
       "   7286,\n",
       "   7287,\n",
       "   7288,\n",
       "   7289,\n",
       "   7290,\n",
       "   7291,\n",
       "   7292,\n",
       "   7293],\n",
       "  43)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results['gap_positions'][0.006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8df7421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"gap_positions.json\", \"w\") as f:\n",
    "    json.dump(all_results['gap_positions'], f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff09ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0.006': {'0': [[1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885], 43], '1': [[2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147], 43], '2': [[5248, 5249, 5250, 5251, 5252, 5253, 5254, 5255, 5256, 5257, 5258, 5259, 5260, 5261, 5262, 5263, 5264, 5265, 5266, 5267, 5268, 5269, 5270, 5271, 5272, 5273, 5274, 5275, 5276, 5277, 5278, 5279, 5280, 5281, 5282, 5283, 5284, 5285, 5286, 5287, 5288, 5289, 5290], 43], '3': [[821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863], 43], '4': [[3719, 3720, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761], 43], '5': [[3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239], 43], '6': [[916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958], 43], '7': [[3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056], 43], '8': [[1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185], 43], '9': [[7251, 7252, 7253, 7254, 7255, 7256, 7257, 7258, 7259, 7260, 7261, 7262, 7263, 7264, 7265, 7266, 7267, 7268, 7269, 7270, 7271, 7272, 7273, 7274, 7275, 7276, 7277, 7278, 7279, 7280, 7281, 7282, 7283, 7284, 7285, 7286, 7287, 7288, 7289, 7290, 7291, 7292, 7293], 43]}, '0.0075': {'0': [[2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829], 54], '1': [[7145, 7146, 7147, 7148, 7149, 7150, 7151, 7152, 7153, 7154, 7155, 7156, 7157, 7158, 7159, 7160, 7161, 7162, 7163, 7164, 7165, 7166, 7167, 7168, 7169, 7170, 7171, 7172, 7173, 7174, 7175, 7176, 7177, 7178, 7179, 7180, 7181, 7182, 7183, 7184, 7185, 7186, 7187, 7188, 7189, 7190, 7191, 7192, 7193, 7194, 7195, 7196, 7197, 7198], 54], '2': [[5256, 5257, 5258, 5259, 5260, 5261, 5262, 5263, 5264, 5265, 5266, 5267, 5268, 5269, 5270, 5271, 5272, 5273, 5274, 5275, 5276, 5277, 5278, 5279, 5280, 5281, 5282, 5283, 5284, 5285, 5286, 5287, 5288, 5289, 5290, 5291, 5292, 5293, 5294, 5295, 5296, 5297, 5298, 5299, 5300, 5301, 5302, 5303, 5304, 5305, 5306, 5307, 5308, 5309], 54], '3': [[4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4601, 4602, 4603, 4604, 4605, 4606, 4607, 4608, 4609], 54], '4': [[5934, 5935, 5936, 5937, 5938, 5939, 5940, 5941, 5942, 5943, 5944, 5945, 5946, 5947, 5948, 5949, 5950, 5951, 5952, 5953, 5954, 5955, 5956, 5957, 5958, 5959, 5960, 5961, 5962, 5963, 5964, 5965, 5966, 5967, 5968, 5969, 5970, 5971, 5972, 5973, 5974, 5975, 5976, 5977, 5978, 5979, 5980, 5981, 5982, 5983, 5984, 5985, 5986, 5987], 54], '5': [[5584, 5585, 5586, 5587, 5588, 5589, 5590, 5591, 5592, 5593, 5594, 5595, 5596, 5597, 5598, 5599, 5600, 5601, 5602, 5603, 5604, 5605, 5606, 5607, 5608, 5609, 5610, 5611, 5612, 5613, 5614, 5615, 5616, 5617, 5618, 5619, 5620, 5621, 5622, 5623, 5624, 5625, 5626, 5627, 5628, 5629, 5630, 5631, 5632, 5633, 5634, 5635, 5636, 5637], 54], '6': [[356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409], 54], '7': [[1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378], 54], '8': [[1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611], 54], '9': [[3973, 3974, 3975, 3976, 3977, 3978, 3979, 3980, 3981, 3982, 3983, 3984, 3985, 3986, 3987, 3988, 3989, 3990, 3991, 3992, 3993, 3994, 3995, 3996, 3997, 3998, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026], 54]}, '0.01': {'0': [[4531, 4532, 4533, 4534, 4535, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4543, 4544, 4545, 4546, 4547, 4548, 4549, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4576, 4577, 4578, 4579, 4580, 4581, 4582, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4596, 4597, 4598, 4599, 4600, 4601, 4602, 4603], 73], '1': [[7226, 7227, 7228, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7236, 7237, 7238, 7239, 7240, 7241, 7242, 7243, 7244, 7245, 7246, 7247, 7248, 7249, 7250, 7251, 7252, 7253, 7254, 7255, 7256, 7257, 7258, 7259, 7260, 7261, 7262, 7263, 7264, 7265, 7266, 7267, 7268, 7269, 7270, 7271, 7272, 7273, 7274, 7275, 7276, 7277, 7278, 7279, 7280, 7281, 7282, 7283, 7284, 7285, 7286, 7287, 7288, 7289, 7290, 7291, 7292, 7293, 7294, 7295, 7296, 7297, 7298], 73], '2': [[816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888], 73], '3': [[390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462], 73], '4': [[6600, 6601, 6602, 6603, 6604, 6605, 6606, 6607, 6608, 6609, 6610, 6611, 6612, 6613, 6614, 6615, 6616, 6617, 6618, 6619, 6620, 6621, 6622, 6623, 6624, 6625, 6626, 6627, 6628, 6629, 6630, 6631, 6632, 6633, 6634, 6635, 6636, 6637, 6638, 6639, 6640, 6641, 6642, 6643, 6644, 6645, 6646, 6647, 6648, 6649, 6650, 6651, 6652, 6653, 6654, 6655, 6656, 6657, 6658, 6659, 6660, 6661, 6662, 6663, 6664, 6665, 6666, 6667, 6668, 6669, 6670, 6671, 6672], 73], '5': [[1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723], 73], '6': [[1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159], 73], '7': [[2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344], 73], '8': [[5606, 5607, 5608, 5609, 5610, 5611, 5612, 5613, 5614, 5615, 5616, 5617, 5618, 5619, 5620, 5621, 5622, 5623, 5624, 5625, 5626, 5627, 5628, 5629, 5630, 5631, 5632, 5633, 5634, 5635, 5636, 5637, 5638, 5639, 5640, 5641, 5642, 5643, 5644, 5645, 5646, 5647, 5648, 5649, 5650, 5651, 5652, 5653, 5654, 5655, 5656, 5657, 5658, 5659, 5660, 5661, 5662, 5663, 5664, 5665, 5666, 5667, 5668, 5669, 5670, 5671, 5672, 5673, 5674, 5675, 5676, 5677, 5678], 73], '9': [[3438, 3439, 3440, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3449, 3450, 3451, 3452, 3453, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3474, 3475, 3476, 3477, 3478, 3479, 3480, 3481, 3482, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510], 73]}, '0.0125': {'0': [[3732, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3748, 3749, 3750, 3751, 3752, 3753, 3754, 3755, 3756, 3757, 3758, 3759, 3760, 3761, 3762, 3763, 3764, 3765, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3774, 3775, 3776, 3777, 3778, 3779, 3780, 3781, 3782, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3793, 3794, 3795, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3805, 3806, 3807, 3808, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3817, 3818, 3819, 3820, 3821, 3822], 91], '1': [[501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591], 91], '2': [[444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534], 91], '3': [[4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507, 4508, 4509, 4510, 4511, 4512, 4513, 4514, 4515, 4516, 4517, 4518, 4519, 4520, 4521, 4522, 4523, 4524, 4525, 4526, 4527, 4528, 4529, 4530, 4531, 4532, 4533, 4534, 4535, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4543, 4544, 4545, 4546, 4547, 4548, 4549, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557], 91], '4': [[5842, 5843, 5844, 5845, 5846, 5847, 5848, 5849, 5850, 5851, 5852, 5853, 5854, 5855, 5856, 5857, 5858, 5859, 5860, 5861, 5862, 5863, 5864, 5865, 5866, 5867, 5868, 5869, 5870, 5871, 5872, 5873, 5874, 5875, 5876, 5877, 5878, 5879, 5880, 5881, 5882, 5883, 5884, 5885, 5886, 5887, 5888, 5889, 5890, 5891, 5892, 5893, 5894, 5895, 5896, 5897, 5898, 5899, 5900, 5901, 5902, 5903, 5904, 5905, 5906, 5907, 5908, 5909, 5910, 5911, 5912, 5913, 5914, 5915, 5916, 5917, 5918, 5919, 5920, 5921, 5922, 5923, 5924, 5925, 5926, 5927, 5928, 5929, 5930, 5931, 5932], 91], '5': [[3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376], 91], '6': [[2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418], 91], '7': [[1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209], 91], '8': [[6656, 6657, 6658, 6659, 6660, 6661, 6662, 6663, 6664, 6665, 6666, 6667, 6668, 6669, 6670, 6671, 6672, 6673, 6674, 6675, 6676, 6677, 6678, 6679, 6680, 6681, 6682, 6683, 6684, 6685, 6686, 6687, 6688, 6689, 6690, 6691, 6692, 6693, 6694, 6695, 6696, 6697, 6698, 6699, 6700, 6701, 6702, 6703, 6704, 6705, 6706, 6707, 6708, 6709, 6710, 6711, 6712, 6713, 6714, 6715, 6716, 6717, 6718, 6719, 6720, 6721, 6722, 6723, 6724, 6725, 6726, 6727, 6728, 6729, 6730, 6731, 6732, 6733, 6734, 6735, 6736, 6737, 6738, 6739, 6740, 6741, 6742, 6743, 6744, 6745, 6746], 91], '9': [[3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3528, 3529, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591], 91]}, '0.015': {'0': [[233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341], 109], '1': [[2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723], 109], '2': [[1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270], 109], '3': [[2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644], 109], '4': [[4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397, 4398, 4399, 4400, 4401, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4441, 4442, 4443, 4444, 4445, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489], 109], '5': [[1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516], 109], '6': [[5702, 5703, 5704, 5705, 5706, 5707, 5708, 5709, 5710, 5711, 5712, 5713, 5714, 5715, 5716, 5717, 5718, 5719, 5720, 5721, 5722, 5723, 5724, 5725, 5726, 5727, 5728, 5729, 5730, 5731, 5732, 5733, 5734, 5735, 5736, 5737, 5738, 5739, 5740, 5741, 5742, 5743, 5744, 5745, 5746, 5747, 5748, 5749, 5750, 5751, 5752, 5753, 5754, 5755, 5756, 5757, 5758, 5759, 5760, 5761, 5762, 5763, 5764, 5765, 5766, 5767, 5768, 5769, 5770, 5771, 5772, 5773, 5774, 5775, 5776, 5777, 5778, 5779, 5780, 5781, 5782, 5783, 5784, 5785, 5786, 5787, 5788, 5789, 5790, 5791, 5792, 5793, 5794, 5795, 5796, 5797, 5798, 5799, 5800, 5801, 5802, 5803, 5804, 5805, 5806, 5807, 5808, 5809, 5810], 109], '7': [[2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387], 109], '8': [[7143, 7144, 7145, 7146, 7147, 7148, 7149, 7150, 7151, 7152, 7153, 7154, 7155, 7156, 7157, 7158, 7159, 7160, 7161, 7162, 7163, 7164, 7165, 7166, 7167, 7168, 7169, 7170, 7171, 7172, 7173, 7174, 7175, 7176, 7177, 7178, 7179, 7180, 7181, 7182, 7183, 7184, 7185, 7186, 7187, 7188, 7189, 7190, 7191, 7192, 7193, 7194, 7195, 7196, 7197, 7198, 7199, 7200, 7201, 7202, 7203, 7204, 7205, 7206, 7207, 7208, 7209, 7210, 7211, 7212, 7213, 7214, 7215, 7216, 7217, 7218, 7219, 7220, 7221, 7222, 7223, 7224, 7225, 7226, 7227, 7228, 7229, 7230, 7231, 7232, 7233, 7234, 7235, 7236, 7237, 7238, 7239, 7240, 7241, 7242, 7243, 7244, 7245, 7246, 7247, 7248, 7249, 7250, 7251], 109], '9': [[4289, 4290, 4291, 4292, 4293, 4294, 4295, 4296, 4297, 4298, 4299, 4300, 4301, 4302, 4303, 4304, 4305, 4306, 4307, 4308, 4309, 4310, 4311, 4312, 4313, 4314, 4315, 4316, 4317, 4318, 4319, 4320, 4321, 4322, 4323, 4324, 4325, 4326, 4327, 4328, 4329, 4330, 4331, 4332, 4333, 4334, 4335, 4336, 4337, 4338, 4339, 4340, 4341, 4342, 4343, 4344, 4345, 4346, 4347, 4348, 4349, 4350, 4351, 4352, 4353, 4354, 4355, 4356, 4357, 4358, 4359, 4360, 4361, 4362, 4363, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4371, 4372, 4373, 4374, 4375, 4376, 4377, 4378, 4379, 4380, 4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4392, 4393, 4394, 4395, 4396, 4397], 109]}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"gap_positions.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35c92d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_lens = [6,9,12,15,18]\n",
    "# Giả sử df là DataFrame với index là năm và cột là tháng\n",
    "df = pd.read_csv(r\"D:\\Learn\\Kì 5\\DPL302m\\Dataset\\PhuLien_bochoi.csv\", index_col=0)  # hoặc dùng read_excel\n",
    "df = df.sort_index()  # đảm bảo theo năm tăng dần\n",
    "\n",
    "# Chuyển thành chuỗi 1 chiều\n",
    "ts = df.values.flatten()  # thành mảng numpy 1D\n",
    "ts=ts[:-3]\n",
    "# ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54d80340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6.0: {0: ([105, 106, 107, 108, 109, 110], 6), 1: ([446, 447, 448, 449, 450, 451], 6), 2: ([512, 513, 514, 515, 516, 517], 6), 3: ([518, 519, 520, 521, 522, 523], 6), 4: ([528, 529, 530, 531, 532, 533], 6), 5: ([469, 470, 471, 472, 473, 474], 6), 6: ([498, 499, 500, 501, 502, 503], 6), 7: ([55, 56, 57, 58, 59, 60], 6), 8: ([409, 410, 411, 412, 413, 414], 6), 9: ([25, 26, 27, 28, 29, 30], 6)}, 9.0: {0: ([186, 187, 188, 189, 190, 191, 192, 193, 194], 9), 1: ([423, 424, 425, 426, 427, 428, 429, 430, 431], 9), 2: ([134, 135, 136, 137, 138, 139, 140, 141, 142], 9), 3: ([290, 291, 292, 293, 294, 295, 296, 297, 298], 9), 4: ([429, 430, 431, 432, 433, 434, 435, 436, 437], 9), 5: ([224, 225, 226, 227, 228, 229, 230, 231, 232], 9), 6: ([67, 68, 69, 70, 71, 72, 73, 74, 75], 9), 7: ([283, 284, 285, 286, 287, 288, 289, 290, 291], 9), 8: ([399, 400, 401, 402, 403, 404, 405, 406, 407], 9), 9: ([261, 262, 263, 264, 265, 266, 267, 268, 269], 9)}, 12.0: {0: ([350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361], 12), 1: ([413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424], 12), 2: ([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267], 12), 3: ([532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543], 12), 4: ([467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478], 12), 5: ([122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133], 12), 6: ([488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499], 12), 7: ([301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312], 12), 8: ([417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428], 12), 9: ([398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409], 12)}, 15.0: {0: ([295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309], 15), 1: ([172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186], 15), 2: ([238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252], 15), 3: ([95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109], 15), 4: ([319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333], 15), 5: ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160], 15), 6: ([521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535], 15), 7: ([296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310], 15), 8: ([234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248], 15), 9: ([406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420], 15)}, 18.0: {0: ([383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400], 18), 1: ([274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291], 18), 2: ([341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358], 18), 3: ([227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244], 18), 4: ([132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149], 18), 5: ([66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83], 18), 6: ([432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449], 18), 7: ([159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176], 18), 8: ([301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318], 18), 9: ([623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640], 18)}}\n"
     ]
    }
   ],
   "source": [
    "with open(r\"D:\\Learn\\Kì 5\\DPL302m\\CODE\\PhuLien_bochoi_gap_positions.json\", \"r\") as f:\n",
    "    Phulien_fixed_positions = json.load(f)\n",
    "\n",
    "# Chuyển key string → float + int (nếu cần)\n",
    "Phulien_fixed_positions = {\n",
    "    float(gap): {int(run): (positions, size)\n",
    "        for run, (positions, size) in run_dict.items()}\n",
    "    for gap, run_dict in Phulien_fixed_positions.items()\n",
    "}\n",
    "print(Phulien_fixed_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b87598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========SVR Results==========\n",
      "\n",
      "==> Gap: 6\n",
      "→ Average metrics: {'SIM': 0.7799390606240956, 'MAE': 16.253665173607672, 'RMSE': 19.928974689085045, 'FB': 0.189922142253831, 'FSD': 0.8003531510592916}\n",
      "\n",
      "==> Gap: 9\n",
      "→ Average metrics: {'SIM': 0.8284960217575849, 'MAE': 16.365628478916832, 'RMSE': 22.74683357240964, 'FB': 0.1688199952778032, 'FSD': 0.7797327982924537}\n",
      "\n",
      "==> Gap: 12\n",
      "→ Average metrics: {'SIM': 0.8671399297325262, 'MAE': 12.136393777458336, 'RMSE': 15.520983623094253, 'FB': 0.08902054682990448, 'FSD': 0.32948055280932065}\n",
      "\n",
      "==> Gap: 15\n",
      "→ Average metrics: {'SIM': 0.8645095609196956, 'MAE': 11.916778598779112, 'RMSE': 14.824501148963458, 'FB': 0.07427634371393368, 'FSD': 0.37662522945414867}\n",
      "\n",
      "==> Gap: 18\n",
      "→ Average metrics: {'SIM': 0.8538795461914453, 'MAE': 15.317577142382135, 'RMSE': 20.831814599563664, 'FB': 0.15099023537987527, 'FSD': 0.43459795173465}\n",
      "\n",
      "==========RF Results==========\n",
      "\n",
      "==> Gap: 6\n",
      "→ Average metrics: {'SIM': 0.7852538393299711, 'MAE': 15.758794097366152, 'RMSE': 18.683558330090943, 'FB': 0.14804130032449797, 'FSD': 0.8925157228305185}\n",
      "\n",
      "==> Gap: 9\n",
      "→ Average metrics: {'SIM': 0.8004413243911872, 'MAE': 19.646700700599677, 'RMSE': 25.50432554566892, 'FB': 0.21527743135365657, 'FSD': 1.0253285788307727}\n",
      "\n",
      "==> Gap: 12\n",
      "→ Average metrics: {'SIM': 0.8720984669981476, 'MAE': 11.784663883112637, 'RMSE': 15.371944680533252, 'FB': 0.08681142645293931, 'FSD': 0.488527976962369}\n",
      "\n",
      "==> Gap: 15\n",
      "→ Average metrics: {'SIM': 0.8708441660641626, 'MAE': 11.231274898400343, 'RMSE': 14.090939041004182, 'FB': 0.06054497405018018, 'FSD': 0.4340139103187986}\n",
      "\n",
      "==> Gap: 18\n",
      "→ Average metrics: {'SIM': 0.866364444231573, 'MAE': 13.894616277808671, 'RMSE': 19.637586216182026, 'FB': 0.1424095209555274, 'FSD': 0.47905242537679016}\n",
      "\n",
      "==========LGBM Results==========\n",
      "\n",
      "==> Gap: 6\n",
      "→ Average metrics: {'SIM': 0.7935336352049445, 'MAE': 15.031339071643178, 'RMSE': 17.954953508626648, 'FB': 0.13092553026664547, 'FSD': 0.6658641499217446}\n",
      "\n",
      "==> Gap: 9\n",
      "→ Average metrics: {'SIM': 0.8083064076490645, 'MAE': 18.768411457574036, 'RMSE': 25.06553138054748, 'FB': 0.21729262538361102, 'FSD': 0.7225118200565204}\n",
      "\n",
      "==> Gap: 12\n",
      "→ Average metrics: {'SIM': 0.8703838447737834, 'MAE': 11.80593708154428, 'RMSE': 15.048214902810262, 'FB': 0.08314987841114628, 'FSD': 0.4126431425296687}\n",
      "\n",
      "==> Gap: 15\n",
      "→ Average metrics: {'SIM': 0.8615460407406633, 'MAE': 12.142686360821298, 'RMSE': 15.07447835669797, 'FB': 0.06458531333053871, 'FSD': 0.3451624809931174}\n",
      "\n",
      "==> Gap: 18\n",
      "→ Average metrics: {'SIM': 0.8650642769825625, 'MAE': 14.01086553309187, 'RMSE': 19.979034631744113, 'FB': 0.13729326060836713, 'FSD': 0.36752115958218634}\n",
      "\n",
      "==========LR Results==========\n",
      "\n",
      "==> Gap: 6\n",
      "→ Average metrics: {'SIM': 0.7776502847781491, 'MAE': 16.748161143985424, 'RMSE': 20.175938401421114, 'FB': 0.16435120990782334, 'FSD': 1.4577134802298368}\n",
      "\n",
      "==> Gap: 9\n",
      "→ Average metrics: {'SIM': 0.8049231740039631, 'MAE': 19.277169405733297, 'RMSE': 25.876150781295745, 'FB': 0.20026202159014145, 'FSD': 1.3768104011969382}\n",
      "\n",
      "==> Gap: 12\n",
      "→ Average metrics: {'SIM': 0.86672431270009, 'MAE': 12.328595205151988, 'RMSE': 16.11891101288872, 'FB': 0.09205796477176775, 'FSD': 0.5368881622868346}\n",
      "\n",
      "==> Gap: 15\n",
      "→ Average metrics: {'SIM': 0.8540964369427396, 'MAE': 12.93709669537385, 'RMSE': 16.062117538644184, 'FB': 0.07066497372857666, 'FSD': 0.5386794297075341}\n",
      "\n",
      "==> Gap: 18\n",
      "→ Average metrics: {'SIM': 0.8586138911230726, 'MAE': 14.770121679039761, 'RMSE': 20.386774011944617, 'FB': 0.15422623680244824, 'FSD': 0.6296811510371934}\n",
      "\n",
      "==========XGB Results==========\n",
      "\n",
      "==> Gap: 6\n",
      "→ Average metrics: {'SIM': 0.764015344584233, 'MAE': 17.87906942932299, 'RMSE': 21.04297210132507, 'FB': 0.16621340105141225, 'FSD': 0.7261940939363577}\n",
      "\n",
      "==> Gap: 9\n",
      "→ Average metrics: {'SIM': 0.804741783509817, 'MAE': 19.50667227938509, 'RMSE': 25.386204393693088, 'FB': 0.19188035117693883, 'FSD': 0.7695580033337249}\n",
      "\n",
      "==> Gap: 12\n",
      "→ Average metrics: {'SIM': 0.8622437245985083, 'MAE': 12.980001582146192, 'RMSE': 16.667579706027738, 'FB': 0.09879752574283909, 'FSD': 0.2957008473792433}\n",
      "\n",
      "==> Gap: 15\n",
      "→ Average metrics: {'SIM': 0.8622053181150356, 'MAE': 12.420005792670521, 'RMSE': 15.979734846894488, 'FB': 0.07488374836997323, 'FSD': 0.37404598331676936}\n",
      "\n",
      "==> Gap: 18\n",
      "→ Average metrics: {'SIM': 0.8636119815920426, 'MAE': 14.45089252036854, 'RMSE': 20.467039531749684, 'FB': 0.13701719266304918, 'FSD': 0.3914055569837115}\n"
     ]
    }
   ],
   "source": [
    "all_results = run_multiple_models(\n",
    "    data=ts,\n",
    "    gap_inputs=gap_lens,\n",
    "    model_types=model_type_list,\n",
    "    input_type='size',\n",
    "    remove_outliers=True,\n",
    "    scale_data=True,\n",
    "    fixed_positions=Phulien_fixed_positions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a9827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6.0: {0: ([105, 106, 107, 108, 109, 110], 6),\n",
       "  1: ([446, 447, 448, 449, 450, 451], 6),\n",
       "  2: ([512, 513, 514, 515, 516, 517], 6),\n",
       "  3: ([518, 519, 520, 521, 522, 523], 6),\n",
       "  4: ([528, 529, 530, 531, 532, 533], 6),\n",
       "  5: ([469, 470, 471, 472, 473, 474], 6),\n",
       "  6: ([498, 499, 500, 501, 502, 503], 6),\n",
       "  7: ([55, 56, 57, 58, 59, 60], 6),\n",
       "  8: ([409, 410, 411, 412, 413, 414], 6),\n",
       "  9: ([25, 26, 27, 28, 29, 30], 6)},\n",
       " 9.0: {0: ([186, 187, 188, 189, 190, 191, 192, 193, 194], 9),\n",
       "  1: ([423, 424, 425, 426, 427, 428, 429, 430, 431], 9),\n",
       "  2: ([134, 135, 136, 137, 138, 139, 140, 141, 142], 9),\n",
       "  3: ([290, 291, 292, 293, 294, 295, 296, 297, 298], 9),\n",
       "  4: ([429, 430, 431, 432, 433, 434, 435, 436, 437], 9),\n",
       "  5: ([224, 225, 226, 227, 228, 229, 230, 231, 232], 9),\n",
       "  6: ([67, 68, 69, 70, 71, 72, 73, 74, 75], 9),\n",
       "  7: ([283, 284, 285, 286, 287, 288, 289, 290, 291], 9),\n",
       "  8: ([399, 400, 401, 402, 403, 404, 405, 406, 407], 9),\n",
       "  9: ([261, 262, 263, 264, 265, 266, 267, 268, 269], 9)},\n",
       " 12.0: {0: ([350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361], 12),\n",
       "  1: ([413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424], 12),\n",
       "  2: ([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267], 12),\n",
       "  3: ([532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543], 12),\n",
       "  4: ([467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478], 12),\n",
       "  5: ([122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133], 12),\n",
       "  6: ([488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499], 12),\n",
       "  7: ([301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312], 12),\n",
       "  8: ([417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428], 12),\n",
       "  9: ([398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409], 12)},\n",
       " 15.0: {0: ([295,\n",
       "    296,\n",
       "    297,\n",
       "    298,\n",
       "    299,\n",
       "    300,\n",
       "    301,\n",
       "    302,\n",
       "    303,\n",
       "    304,\n",
       "    305,\n",
       "    306,\n",
       "    307,\n",
       "    308,\n",
       "    309],\n",
       "   15),\n",
       "  1: ([172,\n",
       "    173,\n",
       "    174,\n",
       "    175,\n",
       "    176,\n",
       "    177,\n",
       "    178,\n",
       "    179,\n",
       "    180,\n",
       "    181,\n",
       "    182,\n",
       "    183,\n",
       "    184,\n",
       "    185,\n",
       "    186],\n",
       "   15),\n",
       "  2: ([238,\n",
       "    239,\n",
       "    240,\n",
       "    241,\n",
       "    242,\n",
       "    243,\n",
       "    244,\n",
       "    245,\n",
       "    246,\n",
       "    247,\n",
       "    248,\n",
       "    249,\n",
       "    250,\n",
       "    251,\n",
       "    252],\n",
       "   15),\n",
       "  3: ([95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
       "   15),\n",
       "  4: ([319,\n",
       "    320,\n",
       "    321,\n",
       "    322,\n",
       "    323,\n",
       "    324,\n",
       "    325,\n",
       "    326,\n",
       "    327,\n",
       "    328,\n",
       "    329,\n",
       "    330,\n",
       "    331,\n",
       "    332,\n",
       "    333],\n",
       "   15),\n",
       "  5: ([146,\n",
       "    147,\n",
       "    148,\n",
       "    149,\n",
       "    150,\n",
       "    151,\n",
       "    152,\n",
       "    153,\n",
       "    154,\n",
       "    155,\n",
       "    156,\n",
       "    157,\n",
       "    158,\n",
       "    159,\n",
       "    160],\n",
       "   15),\n",
       "  6: ([521,\n",
       "    522,\n",
       "    523,\n",
       "    524,\n",
       "    525,\n",
       "    526,\n",
       "    527,\n",
       "    528,\n",
       "    529,\n",
       "    530,\n",
       "    531,\n",
       "    532,\n",
       "    533,\n",
       "    534,\n",
       "    535],\n",
       "   15),\n",
       "  7: ([296,\n",
       "    297,\n",
       "    298,\n",
       "    299,\n",
       "    300,\n",
       "    301,\n",
       "    302,\n",
       "    303,\n",
       "    304,\n",
       "    305,\n",
       "    306,\n",
       "    307,\n",
       "    308,\n",
       "    309,\n",
       "    310],\n",
       "   15),\n",
       "  8: ([234,\n",
       "    235,\n",
       "    236,\n",
       "    237,\n",
       "    238,\n",
       "    239,\n",
       "    240,\n",
       "    241,\n",
       "    242,\n",
       "    243,\n",
       "    244,\n",
       "    245,\n",
       "    246,\n",
       "    247,\n",
       "    248],\n",
       "   15),\n",
       "  9: ([406,\n",
       "    407,\n",
       "    408,\n",
       "    409,\n",
       "    410,\n",
       "    411,\n",
       "    412,\n",
       "    413,\n",
       "    414,\n",
       "    415,\n",
       "    416,\n",
       "    417,\n",
       "    418,\n",
       "    419,\n",
       "    420],\n",
       "   15)},\n",
       " 18.0: {0: ([383,\n",
       "    384,\n",
       "    385,\n",
       "    386,\n",
       "    387,\n",
       "    388,\n",
       "    389,\n",
       "    390,\n",
       "    391,\n",
       "    392,\n",
       "    393,\n",
       "    394,\n",
       "    395,\n",
       "    396,\n",
       "    397,\n",
       "    398,\n",
       "    399,\n",
       "    400],\n",
       "   18),\n",
       "  1: ([274,\n",
       "    275,\n",
       "    276,\n",
       "    277,\n",
       "    278,\n",
       "    279,\n",
       "    280,\n",
       "    281,\n",
       "    282,\n",
       "    283,\n",
       "    284,\n",
       "    285,\n",
       "    286,\n",
       "    287,\n",
       "    288,\n",
       "    289,\n",
       "    290,\n",
       "    291],\n",
       "   18),\n",
       "  2: ([341,\n",
       "    342,\n",
       "    343,\n",
       "    344,\n",
       "    345,\n",
       "    346,\n",
       "    347,\n",
       "    348,\n",
       "    349,\n",
       "    350,\n",
       "    351,\n",
       "    352,\n",
       "    353,\n",
       "    354,\n",
       "    355,\n",
       "    356,\n",
       "    357,\n",
       "    358],\n",
       "   18),\n",
       "  3: ([227,\n",
       "    228,\n",
       "    229,\n",
       "    230,\n",
       "    231,\n",
       "    232,\n",
       "    233,\n",
       "    234,\n",
       "    235,\n",
       "    236,\n",
       "    237,\n",
       "    238,\n",
       "    239,\n",
       "    240,\n",
       "    241,\n",
       "    242,\n",
       "    243,\n",
       "    244],\n",
       "   18),\n",
       "  4: ([132,\n",
       "    133,\n",
       "    134,\n",
       "    135,\n",
       "    136,\n",
       "    137,\n",
       "    138,\n",
       "    139,\n",
       "    140,\n",
       "    141,\n",
       "    142,\n",
       "    143,\n",
       "    144,\n",
       "    145,\n",
       "    146,\n",
       "    147,\n",
       "    148,\n",
       "    149],\n",
       "   18),\n",
       "  5: ([66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83],\n",
       "   18),\n",
       "  6: ([432,\n",
       "    433,\n",
       "    434,\n",
       "    435,\n",
       "    436,\n",
       "    437,\n",
       "    438,\n",
       "    439,\n",
       "    440,\n",
       "    441,\n",
       "    442,\n",
       "    443,\n",
       "    444,\n",
       "    445,\n",
       "    446,\n",
       "    447,\n",
       "    448,\n",
       "    449],\n",
       "   18),\n",
       "  7: ([159,\n",
       "    160,\n",
       "    161,\n",
       "    162,\n",
       "    163,\n",
       "    164,\n",
       "    165,\n",
       "    166,\n",
       "    167,\n",
       "    168,\n",
       "    169,\n",
       "    170,\n",
       "    171,\n",
       "    172,\n",
       "    173,\n",
       "    174,\n",
       "    175,\n",
       "    176],\n",
       "   18),\n",
       "  8: ([301,\n",
       "    302,\n",
       "    303,\n",
       "    304,\n",
       "    305,\n",
       "    306,\n",
       "    307,\n",
       "    308,\n",
       "    309,\n",
       "    310,\n",
       "    311,\n",
       "    312,\n",
       "    313,\n",
       "    314,\n",
       "    315,\n",
       "    316,\n",
       "    317,\n",
       "    318],\n",
       "   18),\n",
       "  9: ([623,\n",
       "    624,\n",
       "    625,\n",
       "    626,\n",
       "    627,\n",
       "    628,\n",
       "    629,\n",
       "    630,\n",
       "    631,\n",
       "    632,\n",
       "    633,\n",
       "    634,\n",
       "    635,\n",
       "    636,\n",
       "    637,\n",
       "    638,\n",
       "    639,\n",
       "    640],\n",
       "   18)}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results['gap_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "205eeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"PhuLien_bochoi_gap_positions.json\", \"w\") as f:\n",
    "    json.dump(all_results['gap_positions'], f, indent=2, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
